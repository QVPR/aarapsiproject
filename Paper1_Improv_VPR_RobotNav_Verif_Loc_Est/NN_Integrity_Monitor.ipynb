{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "%load_ext autoreload\n",
    "# %autoreload 0\n",
    "%autoreload\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrow\n",
    "\n",
    "from pyaarapsi.vpr_simple.vpr_helpers               import FeatureType\n",
    "from pyaarapsi.core.enum_tools                      import enum_get\n",
    "\n",
    "from pyaarapsi.nn.colours import royal_purple, drk_mss_grn, slate_blue, custom_red, gg_bridge\n",
    "from pyaarapsi.nn.nn_helpers import get_td_from_am, get_model_for\n",
    "from pyaarapsi.nn.enums import TrainData, ApplyModel\n",
    "from pyaarapsi.nn.visualize import get_acc_and_confusion_stats, plot_confusion_bars\n",
    "from pyaarapsi.nn.params import General, DFGeneral, DFNNTrain, DFNNTest, NNGeneral\n",
    "\n",
    "from experiment_functions import generate_svm_data, generate_test_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Parameters\n",
    "DF_GENERAL  = DFGeneral()\n",
    "GENERAL     = General()\n",
    "NN_GENERAL  = NNGeneral()\n",
    "DF_NN_TRAIN = DFNNTrain()\n",
    "DF_NN_TEST  = DFNNTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "SHOW_PLOTS = True\n",
    "if True:\n",
    "    train_datas    = [enum_get(value=i, enumtype=TrainData, wrap=False) \n",
    "                        for i in set([\n",
    "                            get_td_from_am(env='Office', apply_model=DF_NN_TRAIN.APPLY_MODEL).name, \n",
    "                            get_td_from_am(env='Campus', apply_model=DF_NN_TRAIN.APPLY_MODEL).name\n",
    "                            ])]\n",
    "    figs = []\n",
    "    figsize = (8,7)\n",
    "    for train_data, feature_type in product(train_datas, DF_GENERAL.FEATURE_TYPES[::-1]):\n",
    "        train_model, train_model_osh = get_model_for(train_data=train_data, \n",
    "            feature_type=feature_type, nn_general=NN_GENERAL, df_nn_train=DF_NN_TRAIN, \n",
    "            general=GENERAL, allow_generate=True)\n",
    "        \n",
    "        train_model_out  = train_model_osh.get_object()['output']\n",
    "        max_epoch        = DF_NN_TRAIN.MAX_EPOCH[feature_type]\n",
    "        \n",
    "        train_losses = np.array(train_model_out['train']['loss'][:max_epoch])\n",
    "        check_losses = np.array(train_model_out['check']['loss'][:max_epoch])\n",
    "\n",
    "        train_bin_labels  = np.array(train_model_out['train']['labels_bin'][:max_epoch])\n",
    "        train_bin_preds   = np.array(train_model_out['train']['pred'][:max_epoch])\n",
    "        check_bin_labels  = np.array(train_model_out['check']['labels_bin'][:max_epoch])\n",
    "        check_bin_preds   = np.array(train_model_out['check']['pred'][:max_epoch])\n",
    "        \n",
    "        train_TP_all_epochs = train_bin_labels * train_bin_preds\n",
    "        train_TN_all_epochs = np.logical_not(train_bin_labels) * np.logical_not(train_bin_preds)\n",
    "        train_FP_all_epochs = np.logical_not(train_bin_labels) * train_bin_preds\n",
    "        train_FN_all_epochs = train_bin_labels * np.logical_not(train_bin_preds)\n",
    "\n",
    "        check_TP_all_epochs = check_bin_labels * check_bin_preds\n",
    "        check_TN_all_epochs = np.logical_not(check_bin_labels) * np.logical_not(check_bin_preds)\n",
    "        check_FP_all_epochs = np.logical_not(check_bin_labels) * check_bin_preds\n",
    "        check_FN_all_epochs = check_bin_labels * np.logical_not(check_bin_preds)\n",
    "        \n",
    "        if SHOW_PLOTS:\n",
    "            figs.append(plt.subplots(2,2, figsize=figsize, sharex=True))\n",
    "\n",
    "            tbl_x = np.arange(len(train_losses))\n",
    "            cbl_x = np.arange(len(check_losses))\n",
    "            figs[-1][1][0][0].plot(tbl_x, np.mean(train_losses, axis=1), 'g-', label='Mean')\n",
    "            figs[-1][1][0][0].plot(tbl_x, np.median(train_losses, axis=1), 'b-', label='Med.')\n",
    "            figs[-1][1][0][0].plot(cbl_x, np.mean(check_losses, axis=1), 'g:', label='Check Mean')\n",
    "            figs[-1][1][0][0].plot(cbl_x, np.median(check_losses, axis=1), 'b:', label='Check Med.')\n",
    "            figs[-1][1][0][1].plot(tbl_x, np.max(train_losses, axis=1), 'g-', label='Max.')\n",
    "            figs[-1][1][0][1].plot(tbl_x, np.min(train_losses, axis=1), 'b-', label='Min.')\n",
    "            figs[-1][1][0][1].plot(cbl_x, np.max(check_losses, axis=1), 'g:', label='Check Max.')\n",
    "            figs[-1][1][0][1].plot(cbl_x, np.min(check_losses, axis=1), 'b:', label='Check Min.')\n",
    "            figs[-1][1][0][0].set_ylabel('Loss per Epoch')\n",
    "            figs[-1][1][0][0].legend()\n",
    "            figs[-1][1][0][1].legend()\n",
    "\n",
    "            figs[-1][1][1][0].plot(tbl_x, np.sum(train_TP_all_epochs, axis=1), 'g', label='TP')\n",
    "            figs[-1][1][1][0].plot(tbl_x, np.sum(train_FN_all_epochs, axis=1), 'r', label='FN')\n",
    "            figs[-1][1][1][0].plot(tbl_x, np.sum(train_FP_all_epochs, axis=1), 'k', label='FP')\n",
    "            figs[-1][1][1][0].plot(tbl_x, np.sum(train_TN_all_epochs, axis=1), 'b', label='TN')\n",
    "            figs[-1][1][1][1].plot(tbl_x, np.sum(check_TP_all_epochs, axis=1), 'g', label='TP')\n",
    "            figs[-1][1][1][1].plot(tbl_x, np.sum(check_FN_all_epochs, axis=1), 'r', label='FN')\n",
    "            figs[-1][1][1][1].plot(tbl_x, np.sum(check_FP_all_epochs, axis=1), 'k', label='FP')\n",
    "            figs[-1][1][1][1].plot(tbl_x, np.sum(check_TN_all_epochs, axis=1), 'b', label='TN')\n",
    "            figs[-1][1][1][0].set_ylabel('Count All Batches')\n",
    "            figs[-1][1][1][0].set_xlabel('Epoch')\n",
    "            figs[-1][1][1][1].set_xlabel('Epoch')\n",
    "            figs[-1][1][1][0].legend()\n",
    "            figs[-1][1][1][1].legend()\n",
    "            figs[-1][1][1][0].set_title('Train')\n",
    "            figs[-1][1][1][1].set_title('Check')\n",
    "            figs[-1][0].suptitle('Feature Type: ' + feature_type.name + ', Apply_Model: ' \n",
    "                                + DF_NN_TRAIN.APPLY_MODEL.name + ', TrainData: ' + train_data.name)\n",
    "            figs[-1][0].subplots_adjust(hspace=0.2)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "PRINT_CONFUSION_SCORES      = True\n",
    "PLOT_PREDICTION_COMPARISON  = True\n",
    "PLOT_CONFUSION_BARS         = True\n",
    "SHOW_TRAIN                  = True\n",
    "SHOW_SVM_SETS               = True\n",
    "SHOW_SETS                   = True\n",
    "FEATURE_TYPE                = FeatureType.SALAD\n",
    "\n",
    "if True: # Huge test battery\n",
    "    '''\n",
    "    \n",
    "    In this section, we generate our test battery. This is fully parameterised, but we currently \n",
    "    have three main results formats that can be generated:\n",
    "    1.  Confusion scores (text to terminal): Prints out the accuracy rate and the true/false \n",
    "        positive/negative rates.\n",
    "            To disable, set PRINT_CONFUSION_SCORES to false.\n",
    "    2.  Prediction comparison (plot): Displays for each data set (might be shuffled for train \n",
    "        depending on earlier settings, typically unshuffled for test) an 'agreement' plot. In blue, \n",
    "        we can see the ground-truth labels. In red, we can see the predicted labels from the neural \n",
    "        network. In an ideal case, we would see symmetry around y=0 (i.e. whenever the label y=1, \n",
    "        the predicted y=-1, and whenever the label y=0, the predicted y=0 as well).\n",
    "            To disable, set PLOT_PREDICTION_COMPARISON to false.\n",
    "    3.  Confusion bars (plot): Displays a bar plot of the confusion scores.\n",
    "            To disable, set PLOT_CONFUSION_BARS to false.\n",
    "\n",
    "    We can also disable outputting for subsets of the data:\n",
    "        To disable training results, set SHOW_TRAIN to false.\n",
    "        To disable SVM dataset testing results, set SHOW_SVM_SETS to false .\n",
    "        To disable all testing results, set SHOW_SETS to false.\n",
    "\n",
    "    We can also control how the model is trained and deployed, broadly.\n",
    "        To use only Campus training data:\n",
    "            Set APPLY_MODEL to Apply_Model.USE_CAMPUS\n",
    "        To use only OFFICE training data:\n",
    "            Set APPLY_MODEL to Apply_Model.USE_OFFICE\n",
    "        To use a fusion of Office and Campus training data:\n",
    "            Set APPLY_MODEL to Apply_Model.USE_FUSED\n",
    "        To use per-environment training data (i.e., Campus SVM on Campus Normal/Adverse, \n",
    "        Office SVM on Office Normal/Adverse):\n",
    "            Set APPLY_MODEL to Apply_Model.MATCH_TO_TRAIN\n",
    "    '''\n",
    "    SVM_DATA, SVM_LENS = generate_svm_data(feature_type=FEATURE_TYPE, general=GENERAL,\n",
    "                                df_general=DF_GENERAL, verbose=GENERAL.NN_IM_SCRIPT_VERBOSE)\n",
    "    TEST_DATA = generate_test_data(feature_type=FEATURE_TYPE, df_nn_test=DF_NN_TEST, \n",
    "                                   df_nn_train=DF_NN_TRAIN, nn_general=NN_GENERAL, general=GENERAL,\n",
    "                                   df_general=DF_GENERAL)\n",
    "    if True:\n",
    "        if True: # set-up\n",
    "            assert (SHOW_SETS == True) or (SHOW_TRAIN == True) or (SHOW_SVM_SETS == True), \\\n",
    "                'Something must get calculated ... ?'\n",
    "\n",
    "            num_train_plots = 2 if DF_NN_TRAIN.APPLY_MODEL.name in \\\n",
    "                                    [ApplyModel.MATCH_TO_TRAIN.name] else 1\n",
    "            num_subplots    = (4 if SHOW_SETS else 0) + (2 if SHOW_SVM_SETS else 0) \\\n",
    "                                + (num_train_plots if SHOW_TRAIN else 0)\n",
    "            subplot_size    = (9, 12 * (num_subplots/7))\n",
    "            yrot = 0\n",
    "            ypad = 90\n",
    "\n",
    "        if PLOT_PREDICTION_COMPARISON: # Initialise prediction comparison figure\n",
    "            fig, ax = plt.subplots(num_subplots, 1, figsize=subplot_size)\n",
    "            if not hasattr(ax, '__iter__'):\n",
    "                ax = [ax]\n",
    "            ax_num = 0\n",
    "\n",
    "        if PLOT_CONFUSION_BARS: # Initialise confusion bars figure\n",
    "            bar_steps = [1,2,3, 5,6,7, 9,10, 12,13,14, 16,17]\n",
    "            bar_group_steps = [2, 6, 9.5, 13, 16.5]\n",
    "            bar_group_labels = [\"Accuracy\\n[%]\", \"True Positive\\nRate [%]\", \n",
    "                                \"True Negative\\nRate [%]\", \"False Positive\\nRate [%]\", \n",
    "                                \"False Negative\\nRate [%]\"]\n",
    "            bar_colors = [royal_purple[0], *royal_purple, drk_mss_grn[0], *drk_mss_grn, \n",
    "                          *slate_blue, custom_red[0], *custom_red, *gg_bridge]\n",
    "            # bar_labels = ['BL\\nAcc.', 'SVM\\nAcc.', 'NN\\nAcc.', 'BL\\nTP', 'SVM\\nTP', 'NN\\nTP', \n",
    "                        # 'SVM\\nTN', 'NN\\nTN', 'BL\\nFP', 'SVM\\nFP', 'NN\\nFP', 'SVM\\nFN.', 'NN\\nFN']\n",
    "            bar_labels = ['BL', 'SVM', 'NN', 'BL', 'SVM', 'NN', 'SVM', 'NN', \n",
    "                          'BL', 'SVM', 'NN', 'SVM', 'NN']\n",
    "            fig1, ax1 = plt.subplots(num_subplots, 1, figsize=subplot_size, sharex=True)\n",
    "            if not hasattr(ax1, '__iter__'):\n",
    "                ax1 = [ax1]\n",
    "            ax_num1 = 0\n",
    "            \n",
    "        if SHOW_TRAIN:\n",
    "            # Generate model and training results\n",
    "            train_models = {}\n",
    "            train_model_oshs = {}\n",
    "            for train_env in ['Office', 'Campus']:\n",
    "                train_data = get_td_from_am(env=train_env, apply_model=DF_NN_TRAIN.APPLY_MODEL)\n",
    "                if not (train_data.value in train_models):\n",
    "                    model, model_osh = get_model_for(train_data=train_data, \n",
    "                        feature_type=FEATURE_TYPE, nn_general=NN_GENERAL, df_nn_train=DF_NN_TRAIN,\n",
    "                        general=GENERAL, allow_generate=True)\n",
    "                    train_models[train_data.value] = model\n",
    "                    train_model_oshs[train_data.value] = model_osh\n",
    "\n",
    "            for train_data_str, model_osh in train_model_oshs.items():\n",
    "                \n",
    "                model_output = model_osh.get_object()['output']\n",
    "                max_epoch    = DF_NN_TRAIN.MAX_EPOCH[feature_type]\n",
    "                result_all   = model_output['train']['result'][max_epoch - 1]\n",
    "                labels_all   = model_output['train']['labels_bin'][max_epoch - 1]\n",
    "                preds_all    = model_output['train']['pred'][max_epoch - 1]\n",
    "\n",
    "                plot_label = 'Training:\\n\\n'+(train_data_str.replace(' ',',\\n')\n",
    "                                              .title().replace('Svm','SVM'))+'\\n\\n'\n",
    "\n",
    "                if PLOT_PREDICTION_COMPARISON:\n",
    "                    ax[ax_num].plot(labels_all, 'b', alpha=0.5)\n",
    "                    ax[ax_num].plot(-1 * np.array(result_all, dtype=float), 'r', alpha=0.1)\n",
    "                    ax[ax_num].plot(-1 * np.array(preds_all, dtype=float), 'r', alpha=0.5)\n",
    "                    ax[ax_num].set_ylabel(plot_label, rotation=yrot, labelpad=ypad,\n",
    "                                          loc = ('bottom' if yrot==0 else 'center'))\n",
    "                    ax_num += 1\n",
    "\n",
    "                if (PLOT_CONFUSION_BARS or PRINT_CONFUSION_SCORES):\n",
    "\n",
    "                    if train_data_str == TrainData.OFFICE_SVM.value:\n",
    "                        s_acc, s_tp, s_tn, s_fp, s_fn  = SVM_DATA['Office']['SVM']\n",
    "                    elif train_data_str == TrainData.CAMPUS_SVM.value:\n",
    "                        s_acc, s_tp, s_tn, s_fp, s_fn  = SVM_DATA['Campus']['SVM']\n",
    "                    elif train_data_str == TrainData.BOTH_SVM.value:\n",
    "                        s_acc, s_tp, s_tn, s_fp, s_fn  = SVM_DATA['Fused']['SVM']\n",
    "                    else: raise Exception(\"Unknown TrainData value: %s\" % train_data_str)\n",
    "\n",
    "                    d_acc, d_tp, d_tn, d_fp, d_fn = get_acc_and_confusion_stats(\n",
    "                                                        label=labels_all, pred=preds_all)\n",
    "                    b_acc, b_tp, b_tn, b_fp, b_fn = get_acc_and_confusion_stats(\n",
    "                                                        label=labels_all, pred=[1]*len(labels_all))\n",
    "\n",
    "                if PLOT_CONFUSION_BARS:\n",
    "                    bar_heights = [b_acc, s_acc, d_acc, b_tp, s_tp, d_tp, s_tn, d_tn, \n",
    "                                   b_fp, s_fp, d_fp, s_fn, d_fn]\n",
    "                    plot_confusion_bars(ax1[ax_num1], bar_heights, bar_steps, bar_colors, \n",
    "                        bar_labels, plot_label, yrot, ypad, ('bottom' if yrot==0 else 'center'))\n",
    "                    ax_num1 += 1\n",
    "\n",
    "                if PRINT_CONFUSION_SCORES:\n",
    "                    print(                 '% 20s Train - Acc: % 7.2f%% [TP: % 7.2f%%, '\n",
    "                                            'TN: % 7.2f%%, FP: % 7.2f%%, FN: % 7.2f%%]' % \n",
    "                                            (train_data_str, d_acc, d_tp, d_tn, d_fp, d_fn))\n",
    "                    print('                       SVM - Acc: % 7.2f%% [TP: % 7.2f%%, '\n",
    "                                            'TN: % 7.2f%%, FP: % 7.2f%%, FN: % 7.2f%%]' % \n",
    "                                            (s_acc, s_tp, s_tn, s_fp, s_fn))\n",
    "                    print('                  Baseline - Acc: % 7.2f%% [TP: % 7.2f%%, '\n",
    "                                            'TN: % 7.2f%%, FP: % 7.2f%%, FN: % 7.2f%%]\\n' % \n",
    "                                            (b_acc, b_tp, b_tn, b_fp, b_fn))\n",
    "\n",
    "        if SHOW_SETS:            \n",
    "            for test_env in ['Office', 'Campus']:\n",
    "                for test_cond in ['Normal', 'Adverse', 'SVM']:\n",
    "\n",
    "                    if (not SHOW_SVM_SETS) and (test_cond == 'SVM'): continue\n",
    "\n",
    "                    test_result = TEST_DATA[test_env][test_cond]['result']\n",
    "                    test_labels = TEST_DATA[test_env][test_cond]['labels_bin']\n",
    "                    test_preds  = TEST_DATA[test_env][test_cond]['pred']\n",
    "\n",
    "                    if PLOT_PREDICTION_COMPARISON:\n",
    "                        ax[ax_num].plot(test_labels, 'b', alpha=0.5)\n",
    "                        ax[ax_num].plot(-1 * np.array(test_result, dtype=float), \n",
    "                                        'r', alpha=0.1)\n",
    "                        ax[ax_num].plot(-1 * np.array(test_preds, dtype=float), \n",
    "                                        'r', alpha=0.5)\n",
    "                        ax[ax_num].set_ylabel('Testing:\\n\\n'+test_env+',\\n'+test_cond+'\\n\\n', \n",
    "                                                rotation=yrot, labelpad=ypad, \n",
    "                                                loc = ('bottom' if yrot==0 else 'center'))\n",
    "                        ax_num += 1\n",
    "\n",
    "                    if PLOT_CONFUSION_BARS or PRINT_CONFUSION_SCORES:\n",
    "                        d_acc, d_tp, d_tn, d_fp, d_fn = get_acc_and_confusion_stats(\n",
    "                            label=test_labels, pred=test_preds)\n",
    "                        s_acc, s_tp, s_tn, s_fp, s_fn = SVM_DATA[test_env][test_cond]\n",
    "                        b_acc, b_tp, b_tn, b_fp, b_fn = get_acc_and_confusion_stats(\n",
    "                            label=test_labels, pred=[1]*len(test_labels))\n",
    "\n",
    "                    if PLOT_CONFUSION_BARS:\n",
    "                        bar_heights = [b_acc, s_acc, d_acc, b_tp, s_tp, d_tp, s_tn, d_tn, \n",
    "                                       b_fp, s_fp, d_fp, s_fn, d_fn]\n",
    "                        plot_confusion_bars(ax1[ax_num1], bar_heights, bar_steps, bar_colors, \n",
    "                            bar_labels, 'Testing:\\n\\n'+test_env+',\\n'+test_cond+'\\n\\n', yrot, \n",
    "                            ypad, ('bottom' if yrot==0 else 'center'))\n",
    "                        ax_num1 += 1\n",
    "\n",
    "                    if PRINT_CONFUSION_SCORES:\n",
    "                        print(         '% 11s, % 7s  Test - Acc: % 7.2f%% [TP: % 7.2f%%, '\n",
    "                                        'TN: % 7.2f%%, FP: % 7.2f%%, FN: % 7.2f%%]' % \n",
    "                                        (test_env, test_cond, d_acc, d_tp, d_tn, d_fp, d_fn))\n",
    "                        print('                       SVM - Acc: % 7.2f%% [TP: % 7.2f%%, '\n",
    "                                        'TN: % 7.2f%%, FP: % 7.2f%%, FN: % 7.2f%%]' % \n",
    "                                        (s_acc, s_tp, s_tn, s_fp, s_fn))\n",
    "                        print('                  Baseline - Acc: % 7.2f%% [TP: % 7.2f%%, '\n",
    "                                        'TN: % 7.2f%%, FP: % 7.2f%%, FN: % 7.2f%%]\\n' % \n",
    "                                        (b_acc, b_tp, b_tn, b_fp, b_fn))\n",
    "                        \n",
    "        if PLOT_PREDICTION_COMPARISON:\n",
    "            ax[0].set_title('Labels in blue, predictions in red.')\n",
    "                        \n",
    "        if PLOT_CONFUSION_BARS:\n",
    "            _formatter              = ticker.FormatStrFormatter(\"%3d%%\")\n",
    "            fig1.subplots_adjust(hspace=0.1)\n",
    "            ax1[0].set_title('Comparison of Baseline VPR (BL), SVM, and MLP Neural Network (NN)\\n'\n",
    "                             'System Performance for Feature Type: ' + FEATURE_TYPE.name + '\\n')\n",
    "            for _ax in ax1:\n",
    "                _ax.set_ylim(0, 150)\n",
    "                _ax.set_yticks([0,25,50,75,100])\n",
    "                _ax.yaxis.set_major_formatter(_formatter)\n",
    "                _ax.spines[['right', 'top']].set_visible(False)\n",
    "            for label, pos in zip(bar_group_labels, bar_group_steps):\n",
    "                ax1[-1].text(pos, -74, label, ha='center')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    del SVM_DATA, SVM_LENS, TEST_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "if True:\n",
    "    fig, ax = plt.subplots(2,2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "\n",
    "    TEST_DATA = generate_test_data(feature_type=FEATURE_TYPE, df_nn_test=DF_NN_TEST, \n",
    "                                   df_nn_train=DF_NN_TRAIN, nn_general=NN_GENERAL, general=GENERAL,\n",
    "                                   df_general=DF_GENERAL)\n",
    "\n",
    "    i = 0\n",
    "    for _env in ['Office', 'Campus']:\n",
    "        for _cond in ['Normal', 'Adverse']:\n",
    "            ds_name = _env + ', ' + _cond\n",
    "\n",
    "            test_model_result_all = np.array(TEST_DATA[_env][_cond]['result'])\n",
    "            test_labels_all       = np.array(TEST_DATA[_env][_cond]['labels'])\n",
    "            print(test_labels_all.shape[0])\n",
    "\n",
    "            test_TP_all = []\n",
    "            test_TN_all = []\n",
    "            test_FP_all = []\n",
    "            test_FN_all = []\n",
    "\n",
    "            num_datapoints = 1000\n",
    "\n",
    "            for j in tqdm(range(num_datapoints)):\n",
    "                thresh                       =  j/num_datapoints\n",
    "                test_model_result_all_thresh =  test_model_result_all >= thresh\n",
    "                test_TP                      =  np.sum(test_labels_all*test_model_result_all_thresh)\n",
    "                test_TN                      =  np.sum(np.logical_not(test_labels_all)*np.logical_not(test_model_result_all_thresh))\n",
    "                test_FP                      =  np.sum(np.logical_not(test_labels_all)*test_model_result_all_thresh)\n",
    "                test_FN                      =  np.sum(test_labels_all*np.logical_not(test_model_result_all_thresh))\n",
    "\n",
    "                test_TP_all.append(test_TP/test_labels_all.shape[0])\n",
    "                test_TN_all.append(test_TN/test_labels_all.shape[0])\n",
    "                test_FP_all.append(test_FP/test_labels_all.shape[0])\n",
    "                test_FN_all.append(test_FN/test_labels_all.shape[0])\n",
    "            \n",
    "            # print(test_TP_all)\n",
    "\n",
    "            # plt.figure()\n",
    "            ax[i//2, i%2].plot(np.arange(num_datapoints)/num_datapoints, np.array(test_TP_all)*100, label='TPs')\n",
    "            ax[i//2, i%2].plot(np.arange(num_datapoints)/num_datapoints, np.array(test_TN_all)*100, label='TNs')\n",
    "            ax[i//2, i%2].plot(np.arange(num_datapoints)/num_datapoints, np.array(test_FP_all)*100, label='FPs')\n",
    "            ax[i//2, i%2].plot(np.arange(num_datapoints)/num_datapoints, np.array(test_FN_all)*100, label='FNs')\n",
    "            ax[i//2, i%2].legend()\n",
    "            ax[i//2, i%2].set_title(ds_name + ' Confusion Operating Curves')\n",
    "            ax[i//2, i%2].set_ylim(0,100)\n",
    "            # plt.xlabel('Integrity Threshold')\n",
    "            # plt.ylabel('Percentage of data')\n",
    "            if i == 0 or i == 2:\n",
    "                ax[i//2, i%2].set_ylabel('Percentage of Data')\n",
    "            if i >= 2:\n",
    "                ax[i//2, i%2].set_xlabel('Integrity Threshold')\n",
    "            i += 1\n",
    "    plt.show()\n",
    "\n",
    "    del TEST_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "if True: # Per featuretype test battery\n",
    "    num_subplots    = 3\n",
    "    subplot_size    = (9, 12 * (num_subplots/7))\n",
    "    _yrot = 0\n",
    "    _ypad = 60\n",
    "    bar_steps = [1,2,3, 5,6,7, 9,10, 12,13,14, 16,17]\n",
    "    bar_group_steps = [2, 6, 9.5, 13, 16.5]\n",
    "    bar_group_labels = [\"Accuracy\\n[%]\", \"True Positive\\nRate [%]\", \"True Negative\\nRate [%]\",\n",
    "                        \"False Positive\\nRate [%]\", \"False Negative\\nRate [%]\"]\n",
    "    bar_colors = [royal_purple[0], *royal_purple, drk_mss_grn[0], *drk_mss_grn, *slate_blue,\n",
    "                    custom_red[0], *custom_red, *gg_bridge]\n",
    "\n",
    "    bar_labels = [  'BL', 'SVM', 'NN', 'BL', 'SVM', 'NN', 'SVM', 'NN',\n",
    "                    'BL', 'SVM', 'NN', 'SVM', 'NN']\n",
    "    fig4, ax4 = plt.subplots(num_subplots, 2, figsize=subplot_size, sharex='col', gridspec_kw={'width_ratios': [1, 4]})\n",
    "    ax_num4 = 0\n",
    "\n",
    "    _aggregates          = {}\n",
    "\n",
    "    for FEATURE_NAME, FEATURE_TYPE in zip(DF_GENERAL.FEATURE_NAMES,DF_GENERAL.FEATURE_TYPES):\n",
    "\n",
    "        TEST_DATA = generate_test_data(feature_type=FEATURE_TYPE, df_nn_test=DF_NN_TEST, \n",
    "                                df_nn_train=DF_NN_TRAIN, nn_general=NN_GENERAL, general=GENERAL,\n",
    "                                df_general=DF_GENERAL)\n",
    "        SVM_DATA, SVM_LENS = generate_svm_data(feature_type=FEATURE_TYPE, general=GENERAL,\n",
    "                                df_general=DF_GENERAL, verbose=GENERAL.NN_IM_SCRIPT_VERBOSE)\n",
    "\n",
    "        _aggregates[FEATURE_TYPE.name] = {k: {'stats': [], 'len': []} for k in 'dsb'}\n",
    "            \n",
    "        for test_env in ['Office', 'Campus']:\n",
    "\n",
    "            train_data = get_td_from_am(env=test_env, apply_model=DF_NN_TRAIN.APPLY_MODEL)\n",
    "            test_nn_model, _ = get_model_for(train_data=train_data, \n",
    "            feature_type=FEATURE_TYPE, nn_general=NN_GENERAL, df_nn_train=DF_NN_TRAIN, \n",
    "            general=GENERAL, allow_generate=True)\n",
    "\n",
    "            test_nn_model.eval() # Inference mode\n",
    "            with torch.no_grad():\n",
    "                test_nn_model_eval = test_nn_model.to(GENERAL.DEVICE)\n",
    "\n",
    "                for test_cond in ['Normal', 'Adverse']:\n",
    "\n",
    "                    test_data = TEST_DATA[test_env][test_cond]\n",
    "                    labels_all = test_data['labels_bin']\n",
    "                    pred_all = test_data['pred']\n",
    "\n",
    "                    _aggregates[FEATURE_TYPE.name]['d']['stats'].append(\n",
    "                        np.array(get_acc_and_confusion_stats(\n",
    "                            label=labels_all,pred=pred_all)))\n",
    "                    _aggregates[FEATURE_TYPE.name]['s']['stats'].append(\n",
    "                        np.array(SVM_DATA[test_env][test_cond]))\n",
    "                    _aggregates[FEATURE_TYPE.name]['b']['stats'].append(\n",
    "                        np.array(get_acc_and_confusion_stats(\n",
    "                            label=labels_all,pred=[1]*len(labels_all))))\n",
    "                    _aggregates[FEATURE_TYPE.name]['d']['len'] \\\n",
    "                        += [len(labels_all)]\n",
    "                    _aggregates[FEATURE_TYPE.name]['s']['len'] \\\n",
    "                        += [SVM_LENS[test_env][test_cond]]\n",
    "                    _aggregates[FEATURE_TYPE.name]['b']['len'] \\\n",
    "                        += [len(labels_all)]\n",
    "        \n",
    "        d_acc, d_tp, d_tn, d_fp, d_fn = tuple(\n",
    "            np.sum(np.array(_aggregates[FEATURE_TYPE.name]['d']['stats']) * \\\n",
    "                    np.array(_aggregates[FEATURE_TYPE.name]['d']['len'])[:,np.newaxis], axis=0) \\\n",
    "                    / np.sum(_aggregates[FEATURE_TYPE.name]['d']['len']))\n",
    "        s_acc, s_tp, s_tn, s_fp, s_fn = tuple(\n",
    "            np.sum(np.array(_aggregates[FEATURE_TYPE.name]['s']['stats']) * \\\n",
    "                    np.array(_aggregates[FEATURE_TYPE.name]['s']['len'])[:,np.newaxis], axis=0) \\\n",
    "                    / np.sum(_aggregates[FEATURE_TYPE.name]['s']['len']))\n",
    "        b_acc, b_tp, b_tn, b_fp, b_fn = tuple(\n",
    "            np.sum(np.array(_aggregates[FEATURE_TYPE.name]['b']['stats']) * \\\n",
    "                    np.array(_aggregates[FEATURE_TYPE.name]['b']['len'])[:,np.newaxis], axis=0) \\\n",
    "                    / np.sum(_aggregates[FEATURE_TYPE.name]['b']['len']))\n",
    "        \n",
    "        bar_heights = [b_acc, s_acc, d_acc, b_tp, s_tp, d_tp, s_tn, d_tn, \n",
    "                        b_fp, s_fp, d_fp, s_fn, d_fn]\n",
    "\n",
    "        ylabel = 'Aggregate\\n'+FEATURE_NAME+\"\\n\\n\"\n",
    "        ax4[ax_num4][0].bar(   x=bar_steps[0:3], color=bar_colors[0:3], height=bar_heights[0:3],\n",
    "                tick_label=bar_labels[0:3])\n",
    "        ax4[ax_num4][1].bar(   x=bar_steps[3:], color=bar_colors[3:], height=bar_heights[3:],\n",
    "                tick_label=bar_labels[3:])\n",
    "        ax4[ax_num4][0].set_ylabel(ylabel, rotation=_yrot, labelpad=_ypad,\n",
    "                                loc=('bottom' if _yrot==0 else 'center'))\n",
    "        for x, y in zip(bar_steps[0:3], bar_heights[0:3]):\n",
    "            ax4[ax_num4][0].text(x, y + 0.1, f\"{y:6.2f}%\", fontsize=8, color='b',\n",
    "                verticalalignment='bottom', horizontalalignment='center', rotation=45)\n",
    "        for x, y in zip(bar_steps[3:], bar_heights[3:]):\n",
    "            ax4[ax_num4][1].text(x, y + 0.1, f\"{y:6.2f}%\", fontsize=8, color='b',\n",
    "                verticalalignment='bottom', horizontalalignment='center', rotation=45)\n",
    "        \n",
    "        ax_num4 += 1\n",
    "                    \n",
    "    _formatter              = ticker.FormatStrFormatter(\"%3d%%\")\n",
    "    fig4.subplots_adjust(hspace=0.1)\n",
    "    fig4.suptitle(\"Comparison of Baseline VPR (BL), SVM, and MLP Neural Network (NN)\"\n",
    "                        \"\\nSystem Performance\")\n",
    "    for _ax in np.array(ax4).flatten().tolist():\n",
    "        _ax.set_ylim(0, 150)\n",
    "        _ax.set_yticks([0,25,50,75,100])\n",
    "        _ax.yaxis.set_major_formatter(_formatter)\n",
    "        _ax.spines[['right', 'top']].set_visible(False)\n",
    "    for label, pos in zip(bar_group_labels[0:1], bar_group_steps[0:1]):\n",
    "        ax4[-1][0].text(pos, -74, label, ha='center')\n",
    "    for label, pos in zip(bar_group_labels[1:], bar_group_steps[1:]):\n",
    "        ax4[-1][1].text(pos, -74, label, ha='center')\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(bar_steps, bar_heights)):\n",
    "        if not i in [2,5,7,10,12]:\n",
    "            continue\n",
    "        for j in [0,1,2]:\n",
    "            if i in [2]:\n",
    "                arrow = FancyArrow(x, 120, 0, 30, width=0.3, head_width=0.6, head_length=10,\n",
    "                                                length_includes_head=True, overhang=0, color='k')\n",
    "                col = 0\n",
    "            elif i in [5,7]:\n",
    "                arrow = FancyArrow(x, 120, 0, 30, width=0.3, head_width=0.6, head_length=10,\n",
    "                                length_includes_head=True, overhang=0, color='k')\n",
    "                col = 1\n",
    "            else:\n",
    "                arrow = FancyArrow(x, 150, 0, -30, width=0.3, head_width=0.6, head_length=10,\n",
    "                                length_includes_head=True, overhang=0, color='k')\n",
    "                col = 1\n",
    "            ax4[j][col].add_patch(arrow)\n",
    "    arrow = FancyArrow(0.16, 0.9, 0.06, -0.03, width=0.003, head_width=0.015, head_length=0.02,\n",
    "                                length_includes_head=True, overhang=0, color='k')\n",
    "    # ax4[0][0].add_patch(arrow)\n",
    "\n",
    "    fig4.add_artist(arrow)\n",
    "\n",
    "    fig4.text(0.027, 0.93, \"This direction for\", fontsize=9)\n",
    "    fig4.text(0.02, 0.9, \"better performance\", fontsize=9)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "path = GENERAL.DIR_MEDIA + '/rr_confusion_comparison' #relative to file directory\n",
    "fig4.savefig(path+'.pdf', format='pdf', dpi=300, pad_inches=0, bbox_inches='tight')\n",
    "fig4.savefig(path+'.png', format='png', dpi=300, pad_inches=0, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
