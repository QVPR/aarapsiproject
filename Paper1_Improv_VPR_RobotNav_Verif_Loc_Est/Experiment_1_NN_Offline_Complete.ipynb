{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a214d1ca-b5c0-4386-aa9b-9555ecd88b1f",
   "metadata": {},
   "source": [
    "# Experiment 1: All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429c713",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a94de9-56ff-4e98-86a0-256b37b1224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "%load_ext autoreload\n",
    "# %autoreload 0\n",
    "%autoreload\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import scienceplots # for ieee style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt, ticker\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from pyaarapsi.nn.visualize import adj_make_split_axes_y_linlog\n",
    "\n",
    "from pyaarapsi.nn.params import DFExperiment1, Experiment1, DFGeneral, General, DFNNTrain, \\\n",
    "    DFNNTest, NNGeneral\n",
    "from experiment_functions import make_load_experiment_1\n",
    "\n",
    "plt.style.use('ieee')\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "EXPERIMENT1     = Experiment1()\n",
    "DF_EXPERIMENT1  = DFExperiment1()\n",
    "DF_GENERAL      = DFGeneral()\n",
    "GENERAL         = General()\n",
    "DF_NN_TRAIN     = DFNNTrain()\n",
    "DF_NN_TEST      = DFNNTest()\n",
    "NN_GENERAL      = NNGeneral()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94751144",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9cdbe",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2574fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_df_features = {}\n",
    "\n",
    "GENERAL.VPR_DP.printer = None if GENERAL.VPRDP_VERBOSE else lambda *args, **kwargs: None\n",
    "GENERAL.VPR_DP.use_tqdm = GENERAL.VPRDP_VERBOSE\n",
    "\n",
    "for FEATURE_TYPE, FEATURE_NAME in zip(DF_GENERAL.FEATURE_TYPES, DF_GENERAL.FEATURE_NAMES):\n",
    "\n",
    "    data = make_load_experiment_1(df_nn_train=DF_NN_TRAIN, df_nn_test=DF_NN_TEST,\n",
    "                                  feature_type=FEATURE_TYPE, general=GENERAL, df_general=DF_GENERAL,\n",
    "                                  df_exp1=DF_EXPERIMENT1, exp1=EXPERIMENT1, nn_general=NN_GENERAL)\n",
    "\n",
    "    data['vprfeaturetype'] = FEATURE_TYPE.name\n",
    "    data['vprfeaturename'] = FEATURE_NAME\n",
    "    data['svmfactor1type'] = DF_NN_TRAIN.VPR.SVM_FACTORS[FEATURE_TYPE.name][0]\n",
    "    data['svmfactor2type'] = DF_NN_TRAIN.VPR.SVM_FACTORS[FEATURE_TYPE.name][1]\n",
    "\n",
    "    _df_features[FEATURE_TYPE.name] = copy.deepcopy(data)\n",
    "    del data\n",
    "\n",
    "del FEATURE_TYPE, FEATURE_NAME\n",
    "\n",
    "df_features = pd.concat([_df_features[i] for i in _df_features.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad2033",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54330e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason, this plot breaks in Seaborn v0.13.0\n",
    "# pip install seaborn==0.12.2; pgrep python | xargs kill -9\n",
    "# then rerun script.\n",
    "\n",
    "if True: # for code folding :-)\n",
    "\n",
    "    _s = 4.5/4.0\n",
    "\n",
    "    fig_m1, axes_m1 = plt.subplots(3,1,figsize=(4*_s,_s*1.1*3), sharex=True)\n",
    "\n",
    "    axes_m1_plotter = lambda ft_type, ax: sns.boxplot(\n",
    "        data=df_features[(df_features['vprfeaturetype']==ft_type) & (df_features.goal_found==True)], \n",
    "        y='abs_overshoot',x='set',hue='filter',ax=ax, palette=GENERAL.PALETTE, whis=1000,\n",
    "        hue_order=GENERAL.HUE_ORDER, order=GENERAL.SET_ORDER, linewidth=0.5, width=0.8,\n",
    "        flierprops=dict(alpha=.05, marker='.', markersize=4, markeredgecolor='none', markerfacecolor='k'),\n",
    "        capprops=dict(color='k'),\n",
    "        boxprops=dict(edgecolor='k'), whiskerprops=dict(color='k'), medianprops=dict(color='k'))\n",
    "\n",
    "    logscale = True\n",
    "    formatter = ticker.FormatStrFormatter(\"%0.1f\")\n",
    "    if logscale:\n",
    "        axes_m1log0 = adj_make_split_axes_y_linlog(axes=axes_m1[0], lims=[-0.1, 1, 205], \n",
    "                        plotter=lambda ax: axes_m1_plotter('APGEM', ax), size=0.3)\n",
    "        axes_m1log1 = adj_make_split_axes_y_linlog(axes=axes_m1[1], lims=[-0.1, 1, 205], \n",
    "                        plotter=lambda ax: axes_m1_plotter('NETVLAD', ax), size=0.3)\n",
    "        axes_m1log2 = adj_make_split_axes_y_linlog(axes=axes_m1[2], lims=[-0.1, 1, 205], \n",
    "                        plotter=lambda ax: axes_m1_plotter('SALAD', ax), size=0.3)\n",
    "        axes_m1log0.yaxis.set_major_formatter(formatter)\n",
    "        axes_m1log1.yaxis.set_major_formatter(formatter)\n",
    "        axes_m1log2.yaxis.set_major_formatter(formatter)\n",
    "        axes_m1log0.tick_params(axis='both', which='both', labelsize=9)\n",
    "        axes_m1log1.tick_params(axis='both', which='both', labelsize=9)\n",
    "        axes_m1log2.tick_params(axis='both', which='both', labelsize=9)\n",
    "\n",
    "    else:\n",
    "        axes_m1_plotter('APGEM', axes_m1[0])\n",
    "        axes_m1[0].set_ylabel('')\n",
    "        axes_m1[0].set_xlabel('')\n",
    "        axes_m1[0].get_legend().set_visible(False)\n",
    "\n",
    "        axes_m1_plotter('NETVLAD', axes_m1[1])\n",
    "        axes_m1[1].set_ylabel('')\n",
    "        axes_m1[1].set_xlabel('')\n",
    "        axes_m1[1].get_legend().set_visible(False)\n",
    "\n",
    "        axes_m1_plotter('SALAD', axes_m1[2])\n",
    "        axes_m1[2].set_ylabel('')\n",
    "        axes_m1[2].set_xlabel('')\n",
    "        axes_m1[2].get_legend().set_visible(False)\n",
    "\n",
    "        axes_m1[0].yaxis.set_major_formatter(formatter)\n",
    "        axes_m1[1].yaxis.set_major_formatter(formatter)\n",
    "        axes_m1[2].yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    axes_m1[0].tick_params(bottom=False)\n",
    "    axes_m1[1].tick_params(bottom=False)\n",
    "\n",
    "    small_frame0 = fig_m1.add_subplot(311, frameon=False)\n",
    "    small_frame1 = fig_m1.add_subplot(312, frameon=False)\n",
    "    small_frame2 = fig_m1.add_subplot(313, frameon=False)\n",
    "\n",
    "    small_frame0.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    small_frame1.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    small_frame2.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "    small_frame0.set_ylabel('APGeM',      fontsize=9, labelpad=5)\n",
    "    small_frame1.set_ylabel('NetVLAD',  fontsize=9, labelpad=5)\n",
    "    small_frame2.set_ylabel('SALAD',    fontsize=9, labelpad=5)\n",
    "\n",
    "    big_frame = fig_m1.add_subplot(111, frameon=False)\n",
    "    big_frame.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    big_frame.set_ylabel('Goal Error (m)',  labelpad=22, fontsize=9)\n",
    "    big_frame.set_title('Experiment 1: Along-Track Goal Error Distribution', fontsize=9)\n",
    "\n",
    "    lgnd = axes_m1[2].legend(loc='lower center', frameon=False, ncol=5, bbox_to_anchor=(0.48,-1.2),\n",
    "                             fontsize=9, labelspacing=0, columnspacing=1.5, handletextpad=0.6)\n",
    "\n",
    "    axes_m1[0].tick_params(axis='both', which='both', labelsize=9)\n",
    "    axes_m1[1].tick_params(axis='both', which='both', labelsize=9)\n",
    "    axes_m1[2].tick_params(axis='both', which='both', labelsize=9)\n",
    "\n",
    "    axes_m1[2].set_xticklabels(['Office\\nNormal','Office\\nAdverse','Campus\\nNormal','Campus\\nAdverse']);#,(rotation=45, ha='right')\n",
    "\n",
    "    fig_m1.subplots_adjust(hspace=0.1)\n",
    "\n",
    "    fig_m1.canvas.draw()\n",
    "\n",
    "\n",
    "    path = GENERAL.DIR_MEDIA + '/exp1_new_extended_key_results_vertical' #relative to file directory\n",
    "    fig_m1.savefig(path+'.pdf', format='pdf', bbox_extra_artists=(lgnd,), dpi=300, pad_inches=0, bbox_inches='tight')\n",
    "    fig_m1.savefig(path+'.png', format='png', bbox_extra_artists=(lgnd,), dpi=300, pad_inches=0, bbox_inches='tight')\n",
    "\n",
    "    # for some Strange reason, on seaborn 0.13.2 these boxplots don't draw correctly in a logscale :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92835aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # for code folding :-)\n",
    "    palette='viridis'\n",
    "\n",
    "    _s = 4.5/4.0\n",
    "    err_kws={\"linestyle\": '-'}\n",
    "    fig,ax=plt.subplots(3,2,figsize=(4*_s,_s*0.8*3),sharex=True,sharey=True)\n",
    "\n",
    "    barplotter = lambda _env, _ft_type, _ax: sns.barplot(\n",
    "        data=df_features[(df_features.environment==_env) & (df_features.vprfeaturetype==_ft_type) & (df_features.mission_impossible==False)],\n",
    "        x='slice_length',y='mission_complete',hue='filter',palette=GENERAL.PALETTE,ax=_ax,\n",
    "        hue_order=GENERAL.HUE_ORDER,errorbar=(\"ci\",95), linewidth=0.1, width=0.8)\n",
    "\n",
    "    f00 = barplotter('Office', 'APGEM',     ax[0][0])\n",
    "    f01 = barplotter('Office', 'NETVLAD',   ax[1][0])\n",
    "    f02 = barplotter('Office', 'SALAD',     ax[2][0])\n",
    "\n",
    "    f10 = barplotter('Campus', 'APGEM',     ax[0][1])\n",
    "    f11 = barplotter('Campus', 'NETVLAD',   ax[1][1])\n",
    "    f12 = barplotter('Campus', 'SALAD',     ax[2][1])\n",
    "\n",
    "    ax[0][0].set_title('Office: Aggregate', fontsize=9)\n",
    "    ax[0][1].set_title('Campus: Aggregate', fontsize=9)\n",
    "\n",
    "    ax[0][0].set_ylabel('APGeM',   fontsize=9, labelpad=5)\n",
    "    ax[1][0].set_ylabel('NetVLAD', fontsize=9, labelpad=5)\n",
    "    ax[2][0].set_ylabel('SALAD',   fontsize=9, labelpad=5)\n",
    "    ax[0][1].set_ylabel('')\n",
    "    ax[1][1].set_ylabel('')\n",
    "    ax[2][1].set_ylabel('')\n",
    "\n",
    "    fs = [f00, f10, f01, f11, f02, f12]\n",
    "\n",
    "    # [i.set(xlabel=None,ylim=(0,1),yticks=[0,0.25,0.5,0.75,1.0],yticklabels=[0,25,50,75,100]) for i in fs]\n",
    "    [i.set(xlabel=None,ylim=(0,1.1),yticks=[0,0.5,1.0],yticklabels=[0,50,100]) for i in fs]\n",
    "    [i.tick_params(bottom=False) for i in fs[0:-2]]\n",
    "    [i.tick_params(left=False) for i in fs[1::2]]\n",
    "    [i.set_xlabel('') for i in fs]\n",
    "    [i.tick_params(axis='both', which='both', labelsize=8) for i in fs]\n",
    "    [i.legend_.remove() for i in fs[:-1]]\n",
    "\n",
    "    for f in fig.get_children():\n",
    "        for i in f.get_children():\n",
    "            if isinstance(i, Line2D):\n",
    "                i._dash_pattern = (0.0, None)\n",
    "                i._linewidth = 1\n",
    "                \n",
    "    _fontdict={\"fontsize\":9}\n",
    "    big_frame = fig.add_subplot(111, frameon=False)\n",
    "    big_frame.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "    big_frame.set_ylabel('Mission Complete (%)',  labelpad=22, fontdict=_fontdict)\n",
    "    big_frame.set_xlabel('Distance to goal (m)',  labelpad=4, fontdict=_fontdict)\n",
    "    big_frame.set_title('Experiment 1: Completed Mission Rates\\n', fontdict=_fontdict)\n",
    "\n",
    "    legend1=ax[2][1].legend(loc='lower center', bbox_to_anchor=(-0.1, -1.1),ncols=5, frameon=False,title='', fontsize=9, \n",
    "                             labelspacing=0, columnspacing=1.5, handletextpad=0.6)\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    path = GENERAL.DIR_MEDIA + '/exp1_new_extended_mission_complete_vertical' #relative to file directory\n",
    "    fig.savefig(path+'.pdf', format='pdf', bbox_extra_artists=(legend1,), dpi=300, pad_inches=0, bbox_inches='tight')\n",
    "    fig.savefig(path+'.png', format='png', bbox_extra_artists=(legend1,), dpi=300, pad_inches=0, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376eb414",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    LATEX_MODE = True\n",
    "    ONLY_AGGREGATES = True\n",
    "    UNDERLINE_MODE = False # latex only\n",
    "\n",
    "    offset = '        '\n",
    "    if LATEX_MODE:\n",
    "        _la  = '% 13s'\n",
    "        _sb  = r'\\B{'\n",
    "        _si  = r'\\I{'\n",
    "        _su  = r'\\U{'\n",
    "        _sn  = r'   '\n",
    "        _eb  = r'm  }'\n",
    "        _ei  = r'm  }'\n",
    "        _en  = r'm   '\n",
    "        _ebp = r'\\% }'\n",
    "        _eip = r'\\% }'\n",
    "        _enp = r'\\%  '\n",
    "        _ee  = r' \\\\'\n",
    "        _sf  = '& % 14s '\n",
    "        if UNDERLINE_MODE:\n",
    "            _si = _su\n",
    "    else:\n",
    "        _la  = '% 11s'\n",
    "        _sb  = r''\n",
    "        _si  = r''\n",
    "        _sn  = r''\n",
    "        _eb  = r'm* '\n",
    "        _ei  = r'm^ '\n",
    "        _en  = r'm  '\n",
    "        _ebp = r'%%*'\n",
    "        _eip = r'%%^'\n",
    "        _enp = r'%% '\n",
    "        _ee  = r'   '\n",
    "        _sf  = '| % 8s '\n",
    "    print()\n",
    "    long_featname = np.max([len(i) for i in DF_GENERAL.FEATURE_NAMES])\n",
    "    df_ = df_features\n",
    "\n",
    "    def make_xfix(_b, _i, _n, c, bests, best_inds, skip_inds):\n",
    "        '''\n",
    "        _b -> prefix if bold\n",
    "        _i -> prefix if italics\n",
    "        _n -> prefix if normal\n",
    "        c  -> index of best_inds in question\n",
    "        '''\n",
    "        italics_inds = []\n",
    "        italics_values = []\n",
    "        bold_inds = []\n",
    "        bold_values = []\n",
    "        bold_first = -1\n",
    "        for p, i in enumerate(best_inds):\n",
    "            if (i not in skip_inds):\n",
    "                if (not bold_inds) or (bests[i] in bold_values):\n",
    "                    bold_inds.append(i)\n",
    "                    bold_values.append(bests[i])\n",
    "                    if bold_first == -1:\n",
    "                        bold_first = p\n",
    "        for p, i in enumerate(best_inds):\n",
    "            if (i in skip_inds):\n",
    "                # if an italics_ind value beats the best bold_value\n",
    "                if ((not italics_inds) and ((p < bold_first) or (bests[i] in bold_values))) \\\n",
    "                    or (bests[i] in italics_values):\n",
    "                    italics_inds.append(i)\n",
    "                    italics_values.append(bests[i])\n",
    "        return _b if c in bold_inds else (_i if c in italics_inds else (_n))\n",
    "\n",
    "    def table_start():\n",
    "        print(r'    \\centering')\n",
    "        print(r'    \\scriptsize')\n",
    "        print(r'    \\setlength\\tabcolsep{1.2mm}')\n",
    "        print(r'    \\begin{tabular}{lcL{11mm}|M{9mm}|M{9mm}M{9mm}|M{9mm}M{9mm}|}')\n",
    "\n",
    "    def table_end(table_label: str):\n",
    "        print(r'    \\end{tabular}')\n",
    "        print(r'    \\label{table:' + table_label + r'}')\n",
    "        print(r'    \\vspace*{-\\baselineskip}')\n",
    "\n",
    "    if LATEX_MODE:\n",
    "        print(r'\\begin{table}[!ht]')\n",
    "        print(r'    \\caption{Experiment 1 along-track goal error and percentage missions '\n",
    "              r'complete (M.C.). Best '\n",
    "              r'performance for each feature type is indicated by bold, ignoring naive '\n",
    "              r'thresholds. Naive thresholds are italicized if best performance.}')\n",
    "        table_start()\n",
    "\n",
    "    thresh_inds = [GENERAL.PRED_TYPES.index('nvp'), GENERAL.PRED_TYPES.index('nvr')]\n",
    "    for featname, feat in zip(DF_GENERAL.FEATURE_NAMES, \n",
    "                                [i.name for i in DF_GENERAL.FEATURE_TYPES]):\n",
    "        if LATEX_MODE:\n",
    "            if feat != DF_GENERAL.FEATURE_TYPES[0].name:\n",
    "                if not ONLY_AGGREGATES:\n",
    "                    print(offset + r'\\hline')\n",
    "            else:\n",
    "                if not ONLY_AGGREGATES:\n",
    "                    print(offset + r'\\cline{3-7}')\n",
    "                else:\n",
    "                    print(offset + r'\\cline{4-8}')\n",
    "            if not ONLY_AGGREGATES:\n",
    "                print(offset + r'& & \\multicolumn{5}{c|}{\\B{' + featname + r' Features}} \\\\')\n",
    "            if feat == DF_GENERAL.FEATURE_TYPES[0].name:\n",
    "                sep = r' & ' if not ONLY_AGGREGATES else r' & & '\n",
    "                print(offset + r'&' + sep \n",
    "                    + r'\\B{Baseline} & \\multicolumn{4}{c|}{\\B{Filtering Technique}} \\\\')\n",
    "                print(offset + r'&' + sep \n",
    "                    + r'\\B{VPR}      & \\boldmath{$N_P$} & '\n",
    "                        r'\\boldmath{$N_R$} & \\B{SVM} & \\B{Ours} \\\\')\n",
    "            print(offset + r'\\hline')\n",
    "        else:\n",
    "            print('\\n' + featname)\n",
    "        for env, cond in product(['Office', 'Campus', 'Aggregate'], ['Normal', 'Adverse']):\n",
    "            if (env == 'Aggregate'): \n",
    "                if (cond == 'Adverse'): break\n",
    "                else: set_name = env\n",
    "            else:\n",
    "                if ONLY_AGGREGATES: continue\n",
    "                set_name = env + '\\n' + cond\n",
    "            \n",
    "            if not (set_name == 'Aggregate'):\n",
    "                df__ = df_[(df_['set'] == set_name) & (df_['vprfeaturetype']==feat)]\n",
    "            else:\n",
    "                df__ = df_[(df_['vprfeaturetype']==feat)]\n",
    "\n",
    "            stats = {}\n",
    "            for label in GENERAL.PRED_TYPES:\n",
    "                stats[label] = {k: np.nan for k in ['gf', 'mc', 'mean', 'med', 'max']}\n",
    "                data = df__[df__['filter'] == GENERAL.MODE_NAMES[label]]\n",
    "                try:\n",
    "                    stats[label]['gf'] = 100 * data[data.goal_found==True].shape[0] / len(data)\n",
    "                    stats[label]['mean'] = np.nanmean(data.abs_overshoot[data.goal_found==True])\n",
    "                    stats[label]['med'] = np.nanmedian(data.abs_overshoot[data.goal_found==True])\n",
    "                    stats[label]['max'] = np.nanmax(data.abs_overshoot[data.goal_found==True])\n",
    "                except (ValueError, ZeroDivisionError):\n",
    "                    pass\n",
    "                try:\n",
    "                    stats[label]['mc'] = 100 * data[data.mission_complete==True].shape[0] \\\n",
    "                                            / len(data)\n",
    "                except (ValueError, ZeroDivisionError):\n",
    "                    pass\n",
    "\n",
    "            num_labels = len(stats.keys())\n",
    "            means = np.round(np.array([stats[label]['mean'] for label in stats.keys()]),2)\n",
    "            means_best = np.argsort(means)\n",
    "            means_str = ''.join([_sf % (make_xfix(_sb, _si, _sn, i, means, means_best, thresh_inds) \n",
    "                                + ('%6.2f' % means[i])\n",
    "                                + make_xfix(_eb, _ei, _en, i, means, means_best, thresh_inds))\n",
    "                                        for i in range(num_labels)])\n",
    "\n",
    "            medis = np.round(np.array([stats[label]['med'] for label in stats.keys()]),2)\n",
    "            medis_best = np.argsort(medis)\n",
    "            medis_str = ''.join([_sf % (make_xfix(_sb, _si, _sn, i, medis, medis_best, thresh_inds) \n",
    "                                + ('%6.2f' % medis[i])\n",
    "                                + make_xfix(_eb, _ei, _en, i, medis, medis_best, thresh_inds))\n",
    "                                        for i in range(num_labels)])\n",
    "\n",
    "            max_s = np.round(np.array([stats[label]['max'] for label in stats.keys()]),2)\n",
    "            max_s_best = np.argsort(max_s)\n",
    "            max_s_str = ''.join([_sf % (make_xfix(_sb, _si, _sn, i, max_s, max_s_best, thresh_inds) \n",
    "                                + ('%6.2f' % max_s[i])\n",
    "                                + make_xfix(_eb, _ei, _en, i, max_s, max_s_best, thresh_inds))\n",
    "                                        for i in range(num_labels)])\n",
    "\n",
    "            gf__s = np.round(np.array([stats[label]['gf'] for label in stats.keys()]),2)\n",
    "            gf__s_best = np.argsort(gf__s)[::-1]\n",
    "            gf__s_str = ''.join([_sf % (make_xfix(_sb, _si, _sn, i, gf__s, gf__s_best, thresh_inds) \n",
    "                                + ('%6.2f' % gf__s[i])\n",
    "                                + make_xfix(_ebp, _eip, _enp, i, gf__s, gf__s_best, thresh_inds))\n",
    "                                        for i in range(num_labels)])\n",
    "            \n",
    "            mc__s = np.round(np.array([stats[label]['mc'] for label in stats.keys()]),2)\n",
    "            mc__s_best = np.argsort(mc__s)[::-1]\n",
    "            mc__s_str = ''.join([_sf % (make_xfix(_sb, _si, _sn, i, mc__s, mc__s_best, thresh_inds) \n",
    "                                + ('%6.2f' % mc__s[i])\n",
    "                                + make_xfix(_ebp, _eip, _enp, i, mc__s, mc__s_best, thresh_inds))\n",
    "                                        for i in range(num_labels)])\n",
    "\n",
    "\n",
    "            _set_name = set_name.replace('\\n',' ')\n",
    "            if not LATEX_MODE:\n",
    "                print(_set_name)\n",
    "                print((' '*7) + ''.join([_la % i \n",
    "                                            for i in ['VPR', 'NVP', 'NVR', 'SVM', 'NN']]))\n",
    "            if LATEX_MODE:\n",
    "                if not ONLY_AGGREGATES:\n",
    "                    _first_whole = r'\\ocMCSMR{1}{|c|}{4}{' + _set_name + r'}' \\\n",
    "                            + (' '*5 if env == 'Aggregate' else \\\n",
    "                                    (' ' if cond == 'Normal' else ''))\n",
    "                    _other = r'\\ocblb'\n",
    "                    _other_whole = _other + (' ' * (len(_first_whole) - len(_other)))\n",
    "                else:\n",
    "                    featname_diff = long_featname - len(featname)\n",
    "                    _first_whole = r'\\ocMCSMRT{2}{|c|}{4}{' + featname + r' Aggregate}' \\\n",
    "                        + (' ' * featname_diff)\n",
    "                    _other = r'\\ocblbT'\n",
    "                    _other_whole = _other + (' ' * (len(_first_whole) - len(_other)))\n",
    "                print(offset + _first_whole + ' &      M.C. ' + mc__s_str + _ee)\n",
    "                print(offset + _other_whole + ' &      Mean ' + means_str + _ee)\n",
    "                print(offset + _other_whole + ' &    Median ' + medis_str + _ee)\n",
    "                print(offset + _other_whole + ' &   Maximum ' + max_s_str + _ee)\n",
    "                if env != 'Aggregate':\n",
    "                    print(offset + '\\hline')\n",
    "            else:\n",
    "                print('Missions Complete: ' + mc__s_str)\n",
    "                print('             Mean: ' + means_str)\n",
    "                print('           Median: ' + medis_str)\n",
    "                print('          Maximum: ' + max_s_str)\n",
    "    if LATEX_MODE:\n",
    "        print(offset + '\\hline')\n",
    "        table_end(\"exp1_summary_new\")\n",
    "        print(r'\\end{table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d0d1b",
   "metadata": {},
   "source": [
    "# Aggregate-Aggregate Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3497be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate-aggregate data:\n",
    "data = df_features[df_features['filter'] == GENERAL.MODE_NAMES['vpr']]\n",
    "vpr_aggregate_gf = 100 * data[data.goal_found==True].shape[0] / len(data)\n",
    "vpr_aggregate_mc = 100 * data[data.mission_complete==True].shape[0] / len(data)\n",
    "vpr_aggregate_mean = np.nanmean(data.abs_overshoot[data.goal_found==True])\n",
    "vpr_aggregate_med = np.nanmedian(data.abs_overshoot[data.goal_found==True])\n",
    "vpr_aggregate_max = np.nanmax(data.abs_overshoot[data.goal_found==True])\n",
    "\n",
    "data = df_features[df_features['filter'] == GENERAL.MODE_NAMES['svm']]\n",
    "svm_aggregate_gf = 100 * data[data.goal_found==True].shape[0] / len(data)\n",
    "svm_aggregate_mc = 100 * data[data.mission_complete==True].shape[0] / len(data)\n",
    "svm_aggregate_mean = np.nanmean(data.abs_overshoot[data.goal_found==True])\n",
    "svm_aggregate_med = np.nanmedian(data.abs_overshoot[data.goal_found==True])\n",
    "svm_aggregate_max = np.nanmax(data.abs_overshoot[data.goal_found==True])\n",
    "\n",
    "data = df_features[df_features['filter'] == GENERAL.MODE_NAMES['prd']]\n",
    "nn_aggregate_gf = 100 * data[data.goal_found==True].shape[0] / len(data)\n",
    "nn_aggregate_mc = 100 * data[data.mission_complete==True].shape[0] / len(data)\n",
    "nn_aggregate_mean = np.nanmean(data.abs_overshoot[data.goal_found==True])\n",
    "nn_aggregate_med = np.nanmedian(data.abs_overshoot[data.goal_found==True])\n",
    "nn_aggregate_max = np.nanmax(data.abs_overshoot[data.goal_found==True])\n",
    "\n",
    "print()\n",
    "print(f'      Experiment 1 Aggregate Statistics Improvement from Baseline VPR')\n",
    "print(f'           ----------------------------------------------------')\n",
    "print(f'                          VPR   :   SVM   :    NN')\n",
    "print(f'           ----------------------------------------------------')\n",
    "print(f'            goal found: {  vpr_aggregate_gf:6.2f}% : {  svm_aggregate_gf:6.2f}% : {  nn_aggregate_gf:6.2f}%')\n",
    "print(f'     missions complete: {  vpr_aggregate_mc:6.2f}% : {  svm_aggregate_mc:6.2f}% : {  nn_aggregate_mc:6.2f}%')\n",
    "print(f'                  mean: {vpr_aggregate_mean:6.2f}m : {svm_aggregate_mean:6.2f}m : {nn_aggregate_mean:6.2f}m')\n",
    "print(f'                median: { vpr_aggregate_med:6.2f}m : { svm_aggregate_med:6.2f}m : { nn_aggregate_med:6.2f}m')\n",
    "print(f'               maximum: { vpr_aggregate_max:6.2f}m : { svm_aggregate_max:6.2f}m : { nn_aggregate_max:6.2f}m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
